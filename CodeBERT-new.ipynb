{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
    "from sentence_transformers import util\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract embeddings from a code snippet or a natural language query.\n",
    "\"\"\"\n",
    "def get_embeddings(text):\n",
    "    tokens_ids = model.tokenize([text],max_length=512,mode=\"<encoder-only>\")\n",
    "    source_ids = torch.tensor(tokens_ids).to(device)\n",
    "    tokens_embeddings,nl_embedding = model(source_ids)\n",
    "    norm_nl_embedding = torch.nn.functional.normalize(nl_embedding, p=2, dim=1)\n",
    "    norm_nl_embedding = norm_nl_embedding.detach().cpu().numpy()[0]\n",
    "    return norm_nl_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nl_query  = 'Plot a histogram'\n",
    "nlq_emb = get_embeddings(nl_query)\n",
    "nlq_emb\n",
    "\n",
    "cos_scores = util.cos_sim(nlq_emb, vector_database)[0]\n",
    "top_results = torch.topk(cos_scores, k=2)\n",
    "\n",
    "# print(top_results)\n",
    "\n",
    "\n",
    "type(torch.return_types.topk(top_results))\n",
    "data = torch.return_types.topk(top_results)\n",
    "print(data)\n",
    "max = data.indices\n",
    "print(max[0])\n",
    "\n",
    "print(code_corpus[max[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_corpus = [\n",
    "\"\"\"\n",
    "class Queue:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "    def is_empty(self):\n",
    "        return self.items == []\n",
    "    def enqueue(self, item):\n",
    "        self.items.insert(0, item)\n",
    "    def dequeue(self):\n",
    "        return self.items.pop()\\\n",
    "    def size(self):\n",
    "        return len(self.items)\n",
    "    def peek(self):\n",
    "        return self.items[-1]\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "print('Hello, world!')\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "num = input('Enter a number: ')\n",
    "\n",
    "print('You Entered:', num)\n",
    "\n",
    "print('Data type of num:', type(num))\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "num1 = 5 \n",
    "num2 = 10 \n",
    "sum = num1 + num2\n",
    "print(\"The sum of\", num1, \"and\", num2, \"is\", sum)\n",
    "\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "num1 = 5 \n",
    "num2 = 10 \n",
    "num3  = 22\n",
    "sum = num1 + num2 + num3\n",
    "print(\"The sum of\", num1, \",\",num3 ,\"and\", num2, \"is\", sum)\n",
    "\n",
    "\"\"\"\n",
    "]\n",
    "vector_database = []\n",
    "for code in code_corpus:\n",
    "    vector_database.append(get_embeddings(code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
